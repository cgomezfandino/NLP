{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carlos Eduardo Gómez Fandiño\n",
    "### Entrega NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción:\n",
    "\n",
    "Con la siguiente practica se busca hacer sentiment Anlaysis (clasificación de mensajes) de un grupo de mensajes (tweets), los cuales se clasificaran entre mensajes positivos y mensajes negativos.\n",
    "El Dataset se obtiene desde la pagina web de Kaggle, que es compartido por la universidad de Michigan (https://inclass.kaggle.com/c/si650winter11/data). Alli podrémos descargar los dos fichero (.txt) en donde estan ya separados entre el test y el train.\n",
    "\n",
    "### Descripción:\n",
    "- El training data contiene 7.086 oraciones la cuales ya se encuentras clasificadas entre positivas o negativas.\n",
    "- Mientras que el test data contiene 33.052 oraciones que no se encuentras con la columna class (que es la que queremos crear con su respectiva clasificación).\n",
    "\n",
    "### Objetivos:\n",
    "\n",
    "- Clasificar mensajes entre positivos y negativos.\n",
    "- Encontrar el mejor algoritmo que permita tener una buena precisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Importación de librarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import urllib\n",
    "import nltk\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_url = \"https://kaggle2.blob.core.windows.net/competitions-data/inclass/2558/testdata.txt?sv=2015-12-11&sr=b&sig=bTkTTpUdXq8xO7feQeI0fTMA6FrQxRFmtbXXPgvaiR4%3D&se=2017-04-12T19%3A18%3A24Z&sp=r\"\n",
    "# train_url = \"https://kaggle2.blob.core.windows.net/competitions-data/inclass/2558/training.txt?sv=2015-12-11&sr=b&sig=qgpxi7tCay5%2FQjbf72ka%2FCSXJ51%2BAHuvvKFfMSSTW1M%3D&se=2017-04-12T19%3A18%3A25Z&sp=r\"  \n",
    "\n",
    "# test = urllib.urlretrieve(test_url, 'test_data.csv')\n",
    "# train = urllib.urlretrieve(train_url, 'train_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test_data.csv', header=None, delimiter = \"\\t\", quoting=3)\n",
    "test_df.columns = ['Text']\n",
    "train_df = pd.read_csv('train_data.csv', header=None, delimiter = \"\\t\", quoting=3)\n",
    "train_df.columns = ['Sentiment' , 'Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\" I don't care what anyone says, I like Hillar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>have an awesome time at purdue!..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yep, I'm still in London, which is pretty awes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Have to say, I hate Paris Hilton's behavior bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i will love the lakers.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  \" I don't care what anyone says, I like Hillar...\n",
       "1                  have an awesome time at purdue!..\n",
       "2  Yep, I'm still in London, which is pretty awes...\n",
       "3  Have to say, I hate Paris Hilton's behavior bu...\n",
       "4                            i will love the lakers."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = list(test_df['Text'])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Da Vinci Code book is just awesome.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this was the first clive cussler i've ever rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>i liked the Da Vinci Code a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>i liked the Da Vinci Code a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I liked the Da Vinci Code but it ultimatly did...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                               Text\n",
       "0          1            The Da Vinci Code book is just awesome.\n",
       "1          1  this was the first clive cussler i've ever rea...\n",
       "2          1                   i liked the Da Vinci Code a lot.\n",
       "3          1                   i liked the Da Vinci Code a lot.\n",
       "4          1  I liked the Da Vinci Code but it ultimatly did..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = list(train_df['Text'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re, nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # remove non letters\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    # tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # stem\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "count_vect = CountVectorizer(analyzer = 'word', tokenizer=tokenize, lowercase=True, stop_words='english', max_features=100)\n",
    "tfidf_vect = TfidfVectorizer(analyzer = 'word', tokenizer=tokenize, lowercase=True, stop_words='english', max_features=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Fitting the dataset\n",
    "# text_tf = count_vect.fit_transform(train_df.Text.tolist() + test_df.Text.tolist())\n",
    "text_train_fit = count_vect.fit(train_df.Text.tolist())\n",
    "# text_test_fit = count_vect.fit(test_df.Text.tolist())\n",
    "\n",
    "# text_tfidf = tfidf_vect.fit_transform(train_df.Text.tolist() + test_df.Text.tolist())\n",
    "text_train_tfidf_fit = tfidf_vect.fit(train_df.Text.tolist())\n",
    "# text_test_tfidf_fit = tfidf_vect.fit(test_df.Text.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Transforming the dataset\n",
    "text_train_trns = text_train_fit.transform(train_df.Text.tolist())\n",
    "# text_test_trns = text_test_fit.transform(test_df.Text.tolist())\n",
    "\n",
    "text_train_tfidf_trns = text_train_tfidf_fit.transform(train_df.Text.tolist())\n",
    "# text_test_tfidf_trns = text_test_tfidf_fit.transform(test_df.Text.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension train (7086L, 100L)\n"
     ]
    }
   ],
   "source": [
    "# text_tf_nd = text_tf.toarray()\n",
    "# text_tf_nd.shape\n",
    "text_train_ft = text_train_trns.toarray()\n",
    "# text_test_ft = text_test_trns.toarray()\n",
    "\n",
    "print 'dimension train', text_train_ft.shape\n",
    "# print 'dimension test',text_test_tf_nd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension train (7086L, 100L)\n"
     ]
    }
   ],
   "source": [
    "# text_tfidf_nd = text_tfidf.toarray()\n",
    "# text_tfidf_nd.shape\n",
    "text_train_tfidf_ft  = text_train_tfidf_trns.toarray()\n",
    "# text_test_tfidf_ft = text_test_tfidf_trns.toarray()\n",
    "print 'dimension train', text_train_tfidf_ft.shape\n",
    "# print 'dimension test',text_test_tfidf_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolut</th>\n",
       "      <th>alway</th>\n",
       "      <th>anyon</th>\n",
       "      <th>awesom</th>\n",
       "      <th>beauti</th>\n",
       "      <th>becaus</th>\n",
       "      <th>better</th>\n",
       "      <th>big</th>\n",
       "      <th>book</th>\n",
       "      <th>bore</th>\n",
       "      <th>...</th>\n",
       "      <th>vinci</th>\n",
       "      <th>wa</th>\n",
       "      <th>wait</th>\n",
       "      <th>want</th>\n",
       "      <th>watch</th>\n",
       "      <th>way</th>\n",
       "      <th>went</th>\n",
       "      <th>whi</th>\n",
       "      <th>worth</th>\n",
       "      <th>yeah</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   absolut  alway  anyon  awesom  beauti  becaus  better  big  book  bore  \\\n",
       "0        0      0      0       1       0       0       0    0     1     0   \n",
       "1        0      0      0       0       0       0       0    0     1     0   \n",
       "2        0      0      0       0       0       0       0    0     0     0   \n",
       "3        0      0      0       0       0       0       0    0     0     0   \n",
       "4        0      0      0       0       0       0       0    0     0     0   \n",
       "\n",
       "   ...   vinci  wa  wait  want  watch  way  went  whi  worth  yeah  \n",
       "0  ...       1   0     0     0      0    0     0    0      0     0  \n",
       "1  ...       1   1     0     0      0    0     0    0      0     0  \n",
       "2  ...       1   0     0     0      0    0     0    0      0     0  \n",
       "3  ...       1   0     0     0      0    0     0    0      0     0  \n",
       "4  ...       1   0     0     0      0    0     0    0      0     0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(text_train_ft, columns=count_vect.get_feature_names())\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolut</th>\n",
       "      <th>alway</th>\n",
       "      <th>anyon</th>\n",
       "      <th>awesom</th>\n",
       "      <th>beauti</th>\n",
       "      <th>becaus</th>\n",
       "      <th>better</th>\n",
       "      <th>big</th>\n",
       "      <th>book</th>\n",
       "      <th>bore</th>\n",
       "      <th>...</th>\n",
       "      <th>vinci</th>\n",
       "      <th>wa</th>\n",
       "      <th>wait</th>\n",
       "      <th>want</th>\n",
       "      <th>watch</th>\n",
       "      <th>way</th>\n",
       "      <th>went</th>\n",
       "      <th>whi</th>\n",
       "      <th>worth</th>\n",
       "      <th>yeah</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.354805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.597834</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.384610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182161</td>\n",
       "      <td>0.226146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   absolut  alway  anyon    awesom  beauti  becaus  better  big      book  \\\n",
       "0      0.0    0.0    0.0  0.354805     0.0     0.0     0.0  0.0  0.597834   \n",
       "1      0.0    0.0    0.0  0.000000     0.0     0.0     0.0  0.0  0.384610   \n",
       "2      0.0    0.0    0.0  0.000000     0.0     0.0     0.0  0.0  0.000000   \n",
       "3      0.0    0.0    0.0  0.000000     0.0     0.0     0.0  0.0  0.000000   \n",
       "4      0.0    0.0    0.0  0.000000     0.0     0.0     0.0  0.0  0.000000   \n",
       "\n",
       "   bore  ...      vinci        wa  wait  want  watch  way  went  whi  worth  \\\n",
       "0   0.0  ...   0.283149  0.000000   0.0   0.0    0.0  0.0   0.0  0.0    0.0   \n",
       "1   0.0  ...   0.182161  0.226146   0.0   0.0    0.0  0.0   0.0  0.0    0.0   \n",
       "2   0.0  ...   0.450416  0.000000   0.0   0.0    0.0  0.0   0.0  0.0    0.0   \n",
       "3   0.0  ...   0.450416  0.000000   0.0   0.0    0.0  0.0   0.0  0.0    0.0   \n",
       "4   0.0  ...   0.300283  0.000000   0.0   0.0    0.0  0.0   0.0  0.0    0.0   \n",
       "\n",
       "   yeah  \n",
       "0   0.0  \n",
       "1   0.0  \n",
       "2   0.0  \n",
       "3   0.0  \n",
       "4   0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(text_train_tfidf_ft, columns=tfidf_vect.get_feature_names()).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'absolut', u'alway', u'anyon', u'awesom', u'beauti', u'becaus', u'better', u'big', u'book', u'bore', u'brokeback', u'care', u'charact', u'cock', u'code', u'cool', u'cowboy', u'da', u'daniel', u'depress', u'die', u'differ', u'doe', u'don', u'excel', u'felicia', u'film', u'friday', u'friend', u'fuck', u'fun', u'gay', u'good', u'got', u'great', u'guy', u'hard', u'harri', u'hate', u'heard', u'hi', u'horribl', u'imposs', u'joke', u'just', u'know', u'left', u'let', u'like', u'love', u'make', u'man', u'mission', u'mom', u'mountain', u'movi', u'na', u'need', u'oh', u'ok', u'onli', u'opinion', u'peopl', u'person', u'place', u'potter', u'read', u'realli', u'review', u'right', u'rock', u's', u'said', u'saw', u'say', u'seen', u'seri', u'start', u'stori', u'stupid', u'suck', u't', u'terribl', u'thi', u'thing', u'think', u'thought', u'time', u'tom', u'turn', u'vinci', u'wa', u'wait', u'want', u'watch', u'way', u'went', u'whi', u'worth', u'yeah']\n"
     ]
    }
   ],
   "source": [
    "vocab = count_vect.get_feature_names()\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cgome\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "# X_train, X_test, y_train, y_test  = train_test_split(text_tf_nd[0:len(train_df)], train_df.Sentiment, train_size=0.80, random_state=1, stratify=train_df.Sentiment)\n",
    "X_train, X_test, y_train, y_test  = train_test_split(text_train_ft, train_df.Sentiment, train_size=0.80, random_state=1, stratify=train_df.Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Create and train the Logistic Regression Classifier\n",
    "log_model = LogisticRegression()\n",
    "log_tf_model = log_model.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = log_tf_model.predict(X=X_test)\n",
    "y_pred_prob = log_tf_model.predict_proba(X=X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.99       619\n",
      "          1       0.99      0.99      0.99       799\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1418\n",
      "\n",
      "accuracy: 0.98872\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(\"accuracy: %0.5f\" % metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Logit_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\" I don't care what anyone says, I like Hillar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>have an awesome time at purdue!..</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yep, I'm still in London, which is pretty awes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Have to say, I hate Paris Hilton's behavior bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i will love the lakers.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Logit_pred\n",
       "0  \" I don't care what anyone says, I like Hillar...           1\n",
       "1                  have an awesome time at purdue!..           1\n",
       "2  Yep, I'm still in London, which is pretty awes...           1\n",
       "3  Have to say, I hate Paris Hilton's behavior bu...           0\n",
       "4                            i will love the lakers.           1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fitted = text_train_fit.transform(test_df.Text)\n",
    "test_fitted_ =test_fitted.toarray()\n",
    "y_pred_test = log_tf_model.predict(X=test_fitted_)\n",
    "test_df['Logit_pred'] = y_pred_test\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Division de pruebas test y train para entrenar el modelo K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(text_train_ft, train_df.Sentiment, train_size=0.80, random_state=1, stratify=train_df.Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k=2\n",
    "km = KMeans(n_clusters=k,max_iter=100)\n",
    "kmeans_model = km.fit(X_train)\n",
    "y_pred = kmeans_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.41      0.66      0.50       619\n",
      "          1       0.49      0.26      0.34       799\n",
      "\n",
      "avg / total       0.45      0.43      0.41      1418\n",
      "\n",
      "accuracy: 0.43159\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(\"accuracy: %0.5f\" % metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Logit_pred</th>\n",
       "      <th>Kmeans_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\" I don't care what anyone says, I like Hillar...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>have an awesome time at purdue!..</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yep, I'm still in London, which is pretty awes...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Have to say, I hate Paris Hilton's behavior bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i will love the lakers.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Logit_pred  Kmeans_pred\n",
       "0  \" I don't care what anyone says, I like Hillar...           1            0\n",
       "1                  have an awesome time at purdue!..           1            0\n",
       "2  Yep, I'm still in London, which is pretty awes...           1            0\n",
       "3  Have to say, I hate Paris Hilton's behavior bu...           0            0\n",
       "4                            i will love the lakers.           1            0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_fitted = text_train_fit.transform(test_df.Text)\n",
    "# test_fitted.toarray()\n",
    "y_pred_km = kmeans_model.predict(X=test_fitted_)\n",
    "test_df['Kmeans_pred'] = y_pred_km\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos el K-means no es un modelo muy bueno ya que tenemos un accuracy del 43%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "tree_mod = ExtraTreesClassifier()\n",
    "tree_model = tree_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99       619\n",
      "          1       0.99      0.99      0.99       799\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1418\n",
      "\n",
      "accuracy: 0.98801\n"
     ]
    }
   ],
   "source": [
    "y_pred = tree_model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(\"accuracy: %0.5f\" % metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que el modelo Extra Trees classifier tiene un accuracy del 98.8%, asi muy parecido al modelo del Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Logit_pred</th>\n",
       "      <th>Kmeans_pred</th>\n",
       "      <th>Tree_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\" I don't care what anyone says, I like Hillar...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>have an awesome time at purdue!..</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yep, I'm still in London, which is pretty awes...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Have to say, I hate Paris Hilton's behavior bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i will love the lakers.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Logit_pred  Kmeans_pred  \\\n",
       "0  \" I don't care what anyone says, I like Hillar...           1            0   \n",
       "1                  have an awesome time at purdue!..           1            0   \n",
       "2  Yep, I'm still in London, which is pretty awes...           1            0   \n",
       "3  Have to say, I hate Paris Hilton's behavior bu...           0            0   \n",
       "4                            i will love the lakers.           1            0   \n",
       "\n",
       "   Tree_pred  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          0  \n",
       "4          1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_fitted = text_train_fit.transform(test_df.Text)\n",
    "# test_fitted.toarray()\n",
    "y_pred_tree = tree_model.predict(test_fitted_)\n",
    "test_df['Tree_pred'] = y_pred_tree\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "X_train, X_test, y_train, y_test  = train_test_split(text_train_ft, train_df.Sentiment, train_size=0.80, random_state=1, stratify=train_df.Sentiment)\n",
    "bayes = GaussianNB()\n",
    "bayes_model = bayes.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.93      0.95       619\n",
      "          1       0.95      0.98      0.96       799\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1418\n",
      "\n",
      "accuracy: 0.95769\n"
     ]
    }
   ],
   "source": [
    "y_pred = bayes_model.predict(X=X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(\"accuracy: %0.5f\" % metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente el modelo Naive Bayes es el tercer mejor modelo de clasificación para sentiment analysis para este trabajo, con un accuracy del 95.76%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Logit_pred</th>\n",
       "      <th>Kmeans_pred</th>\n",
       "      <th>Tree_pred</th>\n",
       "      <th>Bayes_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\" I don't care what anyone says, I like Hillar...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>have an awesome time at purdue!..</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yep, I'm still in London, which is pretty awes...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Have to say, I hate Paris Hilton's behavior bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i will love the lakers.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Logit_pred  Kmeans_pred  \\\n",
       "0  \" I don't care what anyone says, I like Hillar...           1            0   \n",
       "1                  have an awesome time at purdue!..           1            0   \n",
       "2  Yep, I'm still in London, which is pretty awes...           1            0   \n",
       "3  Have to say, I hate Paris Hilton's behavior bu...           0            0   \n",
       "4                            i will love the lakers.           1            0   \n",
       "\n",
       "   Tree_pred  Bayes_pred  \n",
       "0          1           1  \n",
       "1          1           1  \n",
       "2          1           1  \n",
       "3          0           0  \n",
       "4          1           1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_fitted = text_train_fit.transform(test_df.Text)\n",
    "# test_fitted.toarray()\n",
    "y_pred_bayes = bayes_model.predict(X=test_fitted_)\n",
    "test_df['Bayes_pred'] = y_pred_bayes\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A continuación se muestra el ranking de los mejores modelos por accuracy para este trabajo de clasificación de mensajes entre positivos y negativos:\n",
    "1. Logistic Regression: 98.87%\n",
    "1. Extra Trees Classifier: 98.80%\n",
    "1. Naive Bayes: 95.76%\n",
    "1. K-means: 43.15%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
